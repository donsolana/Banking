{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Introduction**\n\nThe purpose of this project is to predict customer salaries based on other features in a given dataset. The data was provided by Austrialian and New Zealand Banking group, and is a synthesized representation of actual transaction information. To achieve this we will use to different models the first being ***multiple regression*** and the other being ***A regression tree model***; which is a decision tree that can produce continous numerical values."},{"metadata":{},"cell_type":"markdown","source":"## Packages\n\nTo complete this analysis we will mainly rely on three main packages namely :\n1. Tidyverse for preprocessing and manipulation\n2. Broom for modeling \n3. ranger for rpart.\n4. rvest for cross validation\n\n"},{"metadata":{"_uuid":"54d6c774-3032-47d0-9a2f-1a8dbe2f8343","_cell_guid":"9194118b-c006-4156-b0de-e983921f23bf","trusted":true},"cell_type":"code","source":"#load the tidyverse,broom, readxl packages\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(readxl)\nlibrary(lubridate)\nlibrary(rpart)\nlibrary(vtreat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anz_xlsx <- \"../input/anz-transaction/anz.xlsx\"\nANZ <- read_excel(anz_xlsx)\n\n#observe file structure\nglimpse(ANZ)\n#print first 10 values\nhead(ANZ, 5)\n#COUNT ROW NUMBERS 12043 rows\nnrow(ANZ)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Data Preprocessing**\nTo perform this analysis we first need to make our data tidy, and search for outliers. This procees can be divided into the three following steps\n1. Search for missing values.\n2. Remove outliers\n3. Extract relevant information."},{"metadata":{"trusted":true},"cell_type":"code","source":"#search for missing values.\n\napply(ANZ, 2, function(x) sum(is.na(x)| x == ''))\n# check the number of unique values for each column\napply(ANZ, 2, function(x) length(unique(x)))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some values are missing especially for merchant information, this is probaly due to the fact that not all transactions where purchase transactions. Its also revealed that they are 100 unique accounts and each transaction was unique. All values are also in the same currency.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# confirm the one -to -one link of account_id and customer_id\nANZ %>% select(account,customer_id) %>%\n unique() %>%\n nrow()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Extracting Relevant Information**\n\nThis data set contains both location and time data, valueable insights might be gotten from them, to extract this information we can use the lubridate package for time date and \"separate\" function  to extract the location information. "},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"\n\n#separate long and lat\nanz <- ANZ %>% separate(\"long_lat\", c(\"c_long\", \"c_lat\"),sep=' ')\n#turn c_long and c_lat into numeric values and re-add them to the data frame\nanz$c_long<- as.numeric(anz$c_long)      \nanz$c_lat <- as.numeric(anz$c_lat)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#extract datetime information and into new columns in the dataset\nanz_timely <- anz %>%\n#mutate() adds new columns and the time related functions help extract information\n                   mutate(datetime = ymd_hms(extraction)) %>%\n                   mutate(time_of_day = ifelse(am(datetime), \"AM\", \"PM\"),\n                          weekday = wday(datetime, label = TRUE),\n                          month = month(datetime, label = TRUE),\n                          date = ymd(date)) \n          \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Removing outliers\n\n We should comb through the data for plausible outliers and normalize the data we can also check if all transactions are in our date and location range.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# check the range of customer location\n# filtering out transactions for those who don't reside in Australia\n anz %>%\n filter (!(c_long >113 & c_long <154 & c_lat > (-44) & c_lat < (-10)))\n#filtering out outlier\nanz_new <- anz_timely %>%\n            filter ((c_long >113 & c_long <154 & c_lat > (-44) & c_lat < (-10)))\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A single customer is from outside australia, so we should exclude all transactions from this account moving forward as these kind of extremeties can affect the accuracy of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"#check date range\nDateRange <- seq(min(anz_new$date), max(anz_new$date), by = 1)\n#  transactions from 2018-08-16 are missing but no transaction is outside the data set.\nDateRange[!DateRange %in% anz_new$date]\n \n\n      \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering\n\nNext we select or generate possible variables from our data set, they will be the \"features\" for our model. We can start by aggregating the total salary for each customer and their total spending. We can also find less salient correlations with the help of *scatterplots*.\n"},{"metadata":{},"cell_type":"markdown","source":"#### **Grouping by Customer ID**\n\nThe data has a column that denotes the customer ID aptly named *customer_id*, we can aggregate data by customer ID and extract information such as:\n* The average balance\n* Relative balance(Balance compared to the median)\n* Total salary\n* Total spending \n* Spending frequency\n\nThe **relative balance** metric is a measure of the total \n\nwe can the help of the ***filter()*** function from the ***dyplr*** package. Alternatively, I suspect that only salary transactions are represented as \"credit\" in the *movement* column, this can make manipulation easier.\n\nSince we are trying to predict salaries we need to a create column for total salary, we can also make one for the frequency of salaries and average balance of the customer. We can create these features separately, then add them together using the ***inner_join*** function from ***dyplr***."},{"metadata":{"trusted":true},"cell_type":"code","source":"#All salary transactions are grouped as \"credit\"   \nanz_new %>% group_by(txn_description, movement) %>% summarize(n())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a new dataframe with total balance\nanz_balance <- anz_new %>%\n                mutate(median_balance = median(balance)) %>%\n                group_by(customer_id) %>% \n                summarize(exp_balance = median(balance),\n                          relative_balance = unique(exp_balance/median_balance),\n                          gender = unique(gender), \n                          age = unique(age),\n                          longitude = unique(c_long),\n                          latitude = unique(c_lat))\n\n\n  \nhead(anz_balance)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a new dataframe for the total salary and spending for each customer,\nanz_aggregate <- anz_new %>%\n                   group_by(customer_id, movement) %>% \n                   summarize(total = sum(amount),\n                             median = median(amount)) %>%\n                   ungroup() %>%\n                   pivot_wider(names_from= c(\"movement\"), values_from = c(\"total\", \"median\")) %>%\n                   transmute(customer_id = customer_id,\n                             spending = total_debit,\n                             salary = total_credit, \n                             median_spending = median_debit)\nhead(anz_aggregate)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The two previous code cells created columns for total salary,total spending,average account balance and other variable that can be used in our model. Next, we join the tables and then find correlations between the explanatory variables(what makes up the prediction) and the response variable(the value we predict), this can be done with the ***inner_join*** function from the ***dypyr*** package."},{"metadata":{"trusted":true},"cell_type":"code","source":"#join the two agreggated dataframe\nanz_sparkly <- anz_balance %>%\n                 inner_join(anz_aggregate, by =  \"customer_id\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Additionally, we can add extra columns indicating the frequency of transactions for each customer."},{"metadata":{"trusted":true},"cell_type":"code","source":"#create new table with columns indicating frequency\nanz_txn_vol <- anz_new %>%  \n                 group_by(customer_id, txn_description) %>%\n                 summarize(txn_volume = n()) %>%\n                 spread(\"txn_description\", \"txn_volume\", fill = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#join all three datasets\nanz_tidy <- anz_sparkly %>% \n             inner_join(anz_txn_vol, by =  \"customer_id\")\n             \n             \nhead(anz_tidy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can visualize the relationship between certain columns and the predictor variable with the help of scatterplots(for continous variables) and boxplots(for categorical variables)."},{"metadata":{},"cell_type":"markdown","source":"### Transaction Against Balance\n\nIn the tables we created, we calculated the total, median and mean balance, we can visualize each variable to determine which of this metrics has the highest correlation. We can create a function that automates a lot of this processes."},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a function that takes a single argument \"x\" that repesents the x-axis of the plot\nggcor<-function(...){ggplot(anz_tidy, aes(..., salary, color = gender)) +\n                       geom_point()\n                       }\n                     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a plot of salary vs. log median_balance)\nggcor(log(exp_balance))\n#correlation between exp_balance and salary\ncor(anz_tidy$exp_balance , anz_tidy$salary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#correlation between log(exp_balance) and salary\ncor(log(anz_tidy$exp_balance) , anz_tidy$salary)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The first plot above shows little positive correlation. However, if a log of the median balance is taken before plotting, an easy to spot pattern will emerge this is because of the nature of the distribution. "},{"metadata":{},"cell_type":"markdown","source":"#### Correlation With Age\n\nThe code cell below showed that there is little correlation between age and salary. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot by age\nggcor(age)\n\nggplot(anz_tidy, aes(age, salary)) + \n  geom_point() +\n  xlim(20, 90)\n\ncor(anz_tidy$age , anz_tidy$salary)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Correlation between Spending and Salary\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot spending vs salary\nggcor(spending)\n\n#spending \ncor(anz_tidy$spending, anz_tidy$salary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#median_spending vs salary\nggcor(median_spending)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transaction volume vs. salary\nggcor(PAYMENT)\ncor(anz_tidy$PAYMENT, anz_tidy$salary)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Relationship Between Location and Salary\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#shows that there is no strong linear relationship between location and salary\ncor(anz_tidy$longitude, anz_tidy$salary)\ncor(anz_tidy$latitude, anz_tidy$salary)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Relationship Between Gender and Salary\n\nThe code cells below show that men in the distribution tend to have a slightly higher salary that others.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"ggplot(anz_tidy, aes(gender, salary)) +\n  geom_boxplot(fill = \"pink\", color = \"blue\") +\n  ggtitle(\"Salary vs. Gender\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the analysis above we can now select the features of the model, they are:\n* gender\n* age\n* expected balance\n* spending(total amount spent)\n* PAYMENT"},{"metadata":{},"cell_type":"markdown","source":"### **Modelling**\n\n#### Modelling with Cross Validation Plan\n\nCreating a kfold cross validation plan is way to validate the modelling processing by testing the models out of sample performance. This can be done with the help of the *kWayCrossValidation* function from the vtreat package. This function splits the data into **K** pairs of training and testing data.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create cross validation plan\nset.seed(2020-10-6,  sample.kind=\"Rounding\")\nsplitplan <- kWayCrossValidation(nrow(anz_tidy), 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train the linear model\n#intialize empty column containing predictions\nanz_tidy$pred_lm <- 0\n\nk <- 3 \nset.seed(2020-10-6,  sample.kind=\"Rounding\")\nfor (i in 1:k){\n    split <- splitplan[[i]]\n    model <- lm(salary ~ factor(gender) + age + log(exp_balance) + spending + PAYMENT, data = anz_tidy[split$train,])\n    anz_tidy$pred_lm[split$app] <- predict(model, newdata = anz_tidy[split$app,])\n }\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#find the RMSE and R-square for the cross validated model.\nanz_tidy %>% \n  summarize(residual_error = (pred_lm - salary)^2,\n            mu =mean(residual_error), \n            rmse = sqrt(mu),\n            y_bar = mean(salary),\n            res = salary - pred_lm,\n            ssr = sum(res^2),\n            sqr_tot = (salary - y_bar)^2,\n            sst = sum(sqr_tot),\n            r_squared = 1- ssr/sst) %>% \n  summarize(rmse = unique(rmse), r_squared = unique(r_squared))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# Use nrow to get the number of rows in anz_tidy and print it\nN <- nrow(anz_tidy)\n\n\n# Create the vector of N uniform random variables\ngp <- runif(N)\n\n# Use gp to create the training set: anz_train (75% of data) and anz_test (25% of data)\nanz_train <- anz_tidy[gp < 0.75, ]\nanz_test <- anz_tidy[gp >= 0.75, ]\n\n#training on a split and test data\nsalary_mod <- lm(salary ~ factor(gender) + age + log(exp_balance) + spending + PAYMENT, data = anz_train)\nglance(salary_mod, data = anz_test) \n\n#the model produced an adj.r.squared value of 0.3414312","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Results \n\nOn the cross-validation test the model had a ***Root Mean Square Error*** of **5772.106 AUD** and a **Coefficient of Determination** of 0.2598248. The root mean square error is a measure of the models accuracy and  its in the same unit as the *response variable*, it can be thought of as the standard error of the models output while the coefficient of determination(R-squared) is a measure of how well the model explains the variance in data, values closer to 1 indicate that model explains variablity in the data well. However, the model performed better on the split and train set and had a lower R-square value, indicating better fit."},{"metadata":{"trusted":true},"cell_type":"code","source":"ggplot(anz_tidy, aes(pred_lm, salary)) +\n geom_point(colour = \"violetred1\") +\n geom_abline(colour = \"darkblue\") +\n xlab(\"Prediction\") +\n ggtitle(\"Ground Truth Vs. Prediction\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  Predicting With Decision Trees\n\nUnlike the linear model, decision trees can capture non-linear relationships, simply, this means the model can be trained to learn patterns that a linear model couldn't. We will construct this model using a grid search method. This simply means we will construct trees with different *hyperparameters*(***presets***) and choose the one that has to lowest error values.\n\nTo accomplish we will follow the following steps:\n1. Split the data into three parts: The training set(70%), the validation set(15%), the test set(10%).\n2. Create a list possible presets.\n3. Create a list of models with each preset\n4. Compute the root mean square error of each model against the validation set.\n5. Select model with the least error.\n6. Make predictions on the test set.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create three random sets from the data\nN <- nrow(anz_tidy)\nrandomizer <- sample(1:3, N, replace = TRUE, prob = c(0.70, 0.15, 0.15))\n\n#Create train set\nanz_tree_train <- anz_tidy[randomizer == 1,]\n\n#Create validation set\nanz_tree_validt <- anz_tidy[randomizer == 2,]\n\n#Create a test set\nanz_tree_test <- anz_tidy[randomizer == 3,]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create a lists of all possible combination.\nminsplit <- seq(5, 10, 1)\nmaxdepth <- seq(5, 15, 1)\ntree_presets <- expand.grid(minsplit = minsplit, maxdepth = maxdepth)\n\n# Number of potential models in the grid\n(num_models <- nrow(tree_presets))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize empty list for models\nanz_tree_models <- list()\n\n#Create a formula for the prediction\nfmla <- salary ~ gender + age + log(exp_balance) + spending + PAYMENT\n\n# Write a loop to create a model for each row in \"tree_presets\"\nfor (i in 1:num_models) {\n\n    # Get minsplit, maxdepth values at row i\n    minsplit <- tree_presets$minsplit[i]\n    maxdepth <- tree_presets$maxdepth[i]\n\n    # Train a model and store in the list\n    anz_tree_models[[i]] <- rpart(formula = fmla, \n                               data = anz_tree_train, \n                               method = \"anova\",\n                               minsplit = minsplit,\n                               maxdepth = maxdepth)\n}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Intialize empty vector for Root_mean_square_error\nRMSE<- c()\n \nfor (i in 1:num_models) {\n    \n    #select the ith model\n    model <- anz_tree_models[[i]]\n    \n     # Make predictions on the validation set with each model \n    pred <- predict(model, anz_tree_validt)\n    \n    # Evaluate predictions\n   RMSE[[i]] <- Metrics::rmse(anz_tree_validt$salary,pred)\n}\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#select the model with the lowest error\n good_tree <- anz_tree_models[[which.min(RMSE)]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test new model \n \npredg <- predict(good_tree, anz_tree_test)\nMetrics::rmse(actual = anz_tree_test$salary, predicted = predg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree Results \n\nThe decision tree produces a similar RMSE value to the linear model at 4758.24 AUD."},{"metadata":{},"cell_type":"markdown","source":"#### Recommendations and Conclusions\n\nBoth the linear model and the decision tree produces relatively high error value and the R-squared value of the linear model indicated that the model cannot explain the variation in the distribution.\n\nA more advanced model with more information such as education and occupation can produce more accurate prediction. \n"}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"}},"nbformat":4,"nbformat_minor":4}