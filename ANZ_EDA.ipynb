{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis for Australia and New Zealand Banking Group\n"},{"metadata":{},"cell_type":"markdown","source":"## **Introduction**\n\n\nThis project aims to garner insights from transaction data, through data manipulation, descriptive statistics and visual exploration. The dataset contained in this project was provided by ***Australia and New Zealand Banking Group*** for a virtual internship program they offer. The data is a synthensized representation of transactions over a three month period. I hope you enjoy following this analysis as much as i enjoyed putting it together.\n\n"},{"metadata":{},"cell_type":"markdown","source":"#### **Visual inspection and Cleaning**\n\nTo begin the exploration, we should start by loading all the required libraries. The package \"tidyverse\" contains a host of libraries with functionalities such as data visualization with ***ggplot2***, data manipulation with ***dplyr***,reading excel files with ***readxl*** and working with dates and time with ***lubridate*** that will be useful for our journey. Next we read-in the data and observe its structure. We should also check the first and last few values to get a feel for the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"#load required library\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(lubridate)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"#read file as \"ANZ\"\nanz_xlsx <- \"../input/anz-transaction/anz.xlsx\"\nANZ <- read_excel(anz_xlsx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#observe file structure\nglimpse(ANZ)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print first 10 values\nhead(ANZ, 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#COUNT ROW NUMBERS 12043 rows\nnrow(ANZ)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check for repeated transactions#\nANZ%>%  group_by(transaction_id) %>%\n  count(sort = TRUE) %>% \n  filter(n > 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The code chunks above reveal that they are 12043 observations(rows) and 23 variables(columns). All 12043 are unique transactions as the code cell above show. The columns *bpay_biller_code* and *merchant_code* seem to be full of null values.A small investigation has revealed that **\"bpay\"** is a payment system, it makes sense that most transactions didn't come through this system. However, futher inspection showed that all entries in those rows are either missing or have the value 0, as such they will be filtered out for the remainder of this analysis.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"#create new dataset without rows with missing values called \"ANZ_sparkly\"\nANZ_sparkly <- ANZ %>% \n                 select(-merchant_code, -bpay_biller_code) \n\n#print new data set\nANZ_sparkly","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Turns out they are still some missing values. However, these values only seem to be missing from \"posted\" transactions. If this is the case it might be that ANZ no longer needs store merchant information after transactions have been confirmed(posted). To confirm whether all missing values are from \"authorised\" transactions run the code cell below."},{"metadata":{"trusted":true},"cell_type":"code","source":"#merchant id and card_present, merchant_surburb, merchant_state, merchant_long_lat are missing for posted transactions.\nANZ_sparkly %>% \n#group data by status column\n group_by(status) %>% \n#count all missing values per status in the listed columns\n summarize(sum(is.na(card_present_flag)),sum(is.na(merchant_id)), sum(is.na(merchant_suburb)), sum(is.na(merchant_long_lat)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before moving forward we should also check if all values are in the same currency we can do this with the help of the R code below."},{"metadata":{"trusted":true},"cell_type":"code","source":"#confirm all transactions are the same currency\n  ANZ_sparkly %>%\n  group_by(currency) %>%\n  count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4326 transactions are \"posted\" and so all merchant information in these transactions are missing, We should only exclude them from any analysis requiring merchant information. This concludes the cleaning portion of our analysis, next we describe the data with some statistics."},{"metadata":{},"cell_type":"markdown","source":"### Descriptive Statistics\n\nThe following code cells contain basic statistics concerning transaction volume"},{"metadata":{"trusted":true},"cell_type":"code","source":"#statistics of transaction volume\nsummary(ANZ_sparkly$amount)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The code block below aggregates the data by movement(credit/debit) and calculates the percentage of the total transaction volume each channel is responsible for. It shows that about 74% of all transactions are credit transactions, while about 26% are credit transactions."},{"metadata":{"trusted":true},"cell_type":"code","source":"#11160 transactions where debits while 883 are credit transactions.\nANZ_sparkly %>% \n  group_by(movement) %>% \n  summarize(amount_per_movement = sum(amount), no_of_transactions = n()) %>%\n  mutate(percentage_movement = amount_per_movement/sum(amount_per_movement) * 100)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Timeseries Analysis\n\nTo analysis the data by time we need to extract information based on the *date* and *extraction* columns in the dataset. The package \"lubridate\" contains functions specially designed for this purpose. The next few code cells below demonstrate this."},{"metadata":{"trusted":true},"cell_type":"code","source":"#extract datetime information and into new columns in the dataset\nANZ_sparkly <- ANZ_sparkly %>%\n                   #mutate() adds new columns and the time related functions help extract information\n                   mutate(datetime = ymd_hms(extraction)) %>%\n                   mutate(\n                     yday = yday(datetime),\n                     hour = hour(datetime),\n                     minute = minute(datetime),\n                     second = second(datetime),\n                     time_of_day = ifelse(am(datetime), \"AM\", \"PM\"),\n                     weekday = wday(datetime, label = TRUE),\n                     month = month(datetime, label = TRUE),\n                     date = ymd(date)\n                          )\n#see new columns\nhead(ANZ_sparkly %>% select(datetime,yday, hour, weekday,time_of_day, month, date))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a more concise data frame for analysis\n#select() helps to choose relevant columns\nANZ_sparkly_analysis <- ANZ_sparkly %>% \n                            select(\n                              status,\n                              account,\n                              balance,\n                              txn_description, \n                              date, \n                              age,\n                              amount,\n                              country,\n                              gender,\n                              movement,\n                              datetime, \n                              hour,\n                              yday,\n                              minute,\n                              second, \n                              time_of_day, \n                              weekday, \n                              month,\n                              date)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have columns with neatly extracted and formated date objects, we can now perform some basic time series analysis. The following code cells are aimed at finding insights such as:\n\n1. The transaction volume per day.\n2. The daily mean and median\n3. The transaction volume per month\n4. the monthly average, maximum, median etc.\n5. The transaction volume per week and other weekly based statistics."},{"metadata":{"trusted":true},"cell_type":"code","source":"#transaction volume by day as \"anz_daily\"\nanz_daily <- ANZ_sparkly %>% \n#group_by(date) instructs R to aggregate data by date in this case\n              group_by(date) %>%\n              summarize(\n               daily_total = sum(amount),\n               daily_mean = mean(amount),\n               daily_median = median(amount),\n               daily_max = max(amount),\n               daily_min = min(amount),\n               daily_sd = sd(amount)) %>% \n mutate(average_daily_transaction = sum(daily_total)/length(date), \n        average_daily_max = mean(daily_max),\n        average_daily_min = mean(daily_min),\n        average_daily_sd = mean(daily_sd), \n        average_daily_mean = mean(daily_mean)) \n#print \"anz_daily\"\nanz_daily","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The table above shows the total transaction volume, maximum transaction and more for each day in the data frame. It also shows the average daily transactions over time. To understand these daily transactions more, we can visualize them.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot daily amount over time, faceted by movement\nggplot(anz_daily, aes(date, daily_total)) + \n  geom_line(col= \"darkblue\") + \n   scale_x_date(date_breaks = \"7 days\" , date_labels = \"%Y-%m-%d\") +\n    theme(axis.text.x = element_text(angle = 65, hjust = 1)) \n     ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"R can help us classify the data by movement type before seeing daily trends"},{"metadata":{"trusted":true},"cell_type":"code","source":"#group_by(date) instructs R to aggregate data by date in this case\nANZ_sparkly %>% \n  group_by(movement,date) %>%\n  summarize(daily_total = sum(amount)) %>%\n  ggplot(aes(date, daily_total)) + \n   geom_line(col = \"darkred\") +\n   scale_x_date(date_breaks = \"10 days\" , date_labels = \"%A\") +\n   theme(axis.text.x = element_text(angle = 65, hjust = 1)) + \n   facet_wrap(~movement)\n   \n\n   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems traffic levels differ with weekdays, to confirm this we can visualize transaction volume by weekday with the help of a barplot."},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot amount by weekday and faceted by movement \nANZ_sparkly %>% \n  group_by(weekday) %>%\n  mutate(amount_by_week = sum(amount)) %>%\n  ungroup()%>%\n  ggplot(aes(weekday,amount_by_week, fill = time_of_day)) + geom_col() +\n  facet_wrap(~movement)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot above revealed that they were no credit transactions on saturdays and sundays, perhaps due to policy or technological constraints. The plot also revealed that the highest volume of transactions occur on friday evenings.The code cells below show the exact figures\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"ANZ_sparkly %>% \n  group_by(weekday,time_of_day) %>%\n  summarise(total = sum(amount), \n            mean = mean(amount),\n            median = median(amount),\n            max = max(amount), \n            min = min(amount),\n            standard_deviation = sd(amount)) %>%\n  ungroup()%>%\n  mutate(percentage_of_transactions = total/sum(total)*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we can repeat the previous analysis and visualizations but by month."},{"metadata":{"trusted":true},"cell_type":"code","source":"#transaction volume by month\nANZ_sparkly %>% \n  group_by(month) %>%\n  summarise(total_per_month = sum(amount),\n            mean_per_month = mean(amount),\n            median_per_month = median(amount),\n            max_per_month = max(amount),\n            min_per_month = min(amount),\n            standard_deviation = sd(amount)) %>%\n  mutate(monthly_average = sum(total_per_month)/3)\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transaction volume by month\nANZ_sparkly %>% \n  group_by(month) %>%\n  mutate(total_per_month = sum(amount)) %>%\n  ungroup() %>%\n  ggplot(aes(month,total_per_month, fill = time_of_day)) + geom_col() +\n  facet_wrap(~movement)\n  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion and recommendations\n\nThe analysis has revealed some valuable insights about the data, including:\n1. The average daily transaction\n2. the total transaction volume per month\n3. the weekday and time periods with the most transaction volumes."}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"}},"nbformat":4,"nbformat_minor":4}